{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Users' Requests Classifier\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "import translators as ts\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_MODEL = r\".\\model.h5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\".\\train_dataset.csv\", delimiter=';')\n",
    "\n",
    "df = shuffle(df)\n",
    "\n",
    "df['Ответ'] = df['Ответ'].where(df['Ответ'] != '1.0', other='n/d')\n",
    "df['Ответ'] = df['Ответ'].where(df['Ответ'] != '0.0', other='n/d')\n",
    "df['Ответ'] = df['Ответ'].where(df['Ответ'] != 'None', other='n/d')\n",
    "df['Ответ'] = df['Ответ'].where(pd.notna(df['Ответ']), other='n/d')\n",
    "df = df.where(df['Ответ'] != 'n/d').dropna(how='all')\n",
    "# df = df.where(df['Unnamed: 0'] == 'original').dropna(how='all')\n",
    "df.index = range(len(df['Ответ']))\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "WORD_PATTERN = re.compile(r'\\w+', re.IGNORECASE)\n",
    "\n",
    "def stem(ser):\n",
    "    for i in range(len(ser)):\n",
    "        stc = re.findall(WORD_PATTERN, ser[i])\n",
    "        stc = [stemmer.stem(w) for w in stc]\n",
    "        ser[i] = ' '.join(stc)\n",
    "    return ser\n",
    "\n",
    "df['Обращение'] = stem(df['Обращение'])\n",
    "df['Вопрос'] = stem(df['Вопрос'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Natural Language Processing\n",
    "#### Term frequency-inverse document frequency\n",
    "- Частота слова (Term Frequency) — подсчитывает, как часто выбранное слово появляется в документе.\n",
    "- Обратная частота документа (Inverse Document Frequency) — снижает вес слов, которые часто встречаются в документах.\n",
    "\n",
    "В дальнейшем результаты могут быть улучшены использованием Word2vec - отображения слов в соответствующие n-мерные векторы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "_ = tfidf.fit(df['Обращение'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_encoder = LabelEncoder()\n",
    "_ = group_encoder.fit(df['Тип обращения'])\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "_ = label_encoder.fit(df['Ответ'])\n",
    "train_labels = label_encoder.transform(df['Ответ'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert data to more efficient form\n",
    "- English translation\n",
    "- Vectorizing\n",
    "- Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(raw: pd.DataFrame, translate=False) -> pd.DataFrame:\n",
    "    data_raw = raw[['Обращение', 'Тип обращения']].copy(True)\n",
    "    data_raw['Тип обращения'] = group_encoder.transform(data_raw['Тип обращения'])\n",
    "    \n",
    "    if translate:\n",
    "        for i in range(len(data_raw['Обращение'])):\n",
    "            data_raw['Обращение'][i] = ts.google(data_raw['Обращение'][i], if_use_cn_host=True)\n",
    "            if len(data_raw['Обращение']) > 25:\n",
    "                print('{}/{}'.format(i + 1, len(data_raw['Обращение'])), end='\\r')\n",
    "        if len(data_raw['Обращение']) > 25:\n",
    "            print()\n",
    "        tr = data_raw.copy(True)\n",
    "    \n",
    "    data_v = pd.DataFrame(tfidf.transform(data_raw['Обращение']).toarray())\n",
    "    data = data_v.join(data_raw['Тип обращения'])\n",
    "    \n",
    "    if translate:\n",
    "        return data, tr\n",
    "    else:\n",
    "        return data\n",
    "\n",
    "df_prep = prepare_data(df[['Обращение', 'Тип обращения']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and fit Neural Network model\n",
    "- 3x Dense layers\n",
    "- Crossentropy loss function: sparse_categorical_crossentropy\n",
    "- Optimizer: adam\n",
    "- Stop training when a loss metric has stopped improving\n",
    "- Load pretrained model if exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(PATH_MODEL):\n",
    "    clf = Sequential()\n",
    "    clf.add(Dense(1024*2, input_dim=df_prep.shape[1], activation='relu'))\n",
    "    clf.add(Dense(512*2, activation='relu'))\n",
    "    clf.add(Dense(len(label_encoder.classes_), activation='softmax'))\n",
    "\n",
    "    callback = EarlyStopping(monitor='loss', patience=2)\n",
    "\n",
    "    clf.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    _ = clf.fit(df_prep, train_labels, epochs=30, callbacks=[callback], batch_size=2)\n",
    "    clf.save(PATH_MODEL)\n",
    "else:\n",
    "    clf = load_model(PATH_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on data\n",
    "Features: 'Обращение', 'Тип обращения'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classificate(data):\n",
    "    test_data = pd.DataFrame(data, columns=['Обращение', 'Тип обращения'])\n",
    "    test_data['Обращение'] = stem(test_data['Обращение'])\n",
    "\n",
    "    test_data_prep, test_data_tr = prepare_data(test_data, translate=True)\n",
    "    preds_proba = clf.predict(test_data_prep)\n",
    "\n",
    "    preds = preds_proba.argmax(axis=1)\n",
    "    preds_lab = label_encoder.inverse_transform(preds)\n",
    "    \n",
    "    return preds_lab, preds_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50\n",
      "accuracy_score       : 0.4200\n"
     ]
    }
   ],
   "source": [
    "test_data = pd.read_csv(r'.\\test_dataset.csv')\n",
    "test_data = shuffle(test_data)\n",
    "\n",
    "drop_to = list()\n",
    "for i in range(len(test_data['Ответ'])):\n",
    "    if str(test_data['Ответ'][i]) not in [x for x in df['Ответ']]:\n",
    "        drop_to.append(i)\n",
    "\n",
    "test_data = test_data.drop(index=drop_to)\n",
    "test_data.index = range(len(test_data['Ответ']))\n",
    "\n",
    "test_labels = label_encoder.transform(test_data['Ответ'])\n",
    "test_data = test_data.drop(columns=['Ответ'])\n",
    "\n",
    "test_data_prep, test_data_tr = prepare_data(test_data, translate=True)\n",
    "\n",
    "preds_proba = clf.predict(test_data_prep)\n",
    "\n",
    "print('{:20} : {:1.4f}'.format('accuracy_score', metrics.accuracy_score(test_labels, preds_proba.argmax(axis=1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monitor users' requests database\n",
    "Send back predicted answers and its probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-e300bb7567a3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpost\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'http://77.222.54.233/result.php'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreply\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m     \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    request = requests.get('http://77.222.54.233/requests.php')\n",
    "    request = request.json() if len(request.content) else list()\n",
    "    if len(request):\n",
    "        print(request)\n",
    "    \n",
    "    req_data = list()\n",
    "    for req in request:\n",
    "        msg = req['msg']\n",
    "        theme = req['theme'] if (req['theme'] is not None and len(req['theme'])) else 'Интернет'\n",
    "        req_data.append([msg, theme])\n",
    "    \n",
    "    if len(req_data):\n",
    "        labs, probas = classificate(req_data)\n",
    "\n",
    "        reply = {\"answer\": []}\n",
    "        for i in range(len(request)):\n",
    "            reply[\"answer\"].append(\n",
    "            {\n",
    "                'id': request[i]['id'], \n",
    "                'result': labs[i], \n",
    "                'prob': float(probas[i].max())\n",
    "            })\n",
    "            \n",
    "        print(reply[\"answer\"])\n",
    "        reply[\"answer\"] = json.dumps(reply[\"answer\"])\n",
    "\n",
    "        resp = requests.post('http://77.222.54.233/result.php', data=reply)\n",
    "    \n",
    "    time.sleep(0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
